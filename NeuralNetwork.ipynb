{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import gc\n",
    "import time\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from pyod.utils.example import visualize\n",
    "import warnings\n",
    "import matplotlib.font_manager\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"C:/Users/Enduser/OneDrive - Asia Pacific University/uni/Y3S2/fyp/Model_trial/btc_trial_dataset2.csv\"\n",
    "dataset_df = pd.read_csv(df_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['tx_hash', 'is_malicious', 'all_malicious', 'mean_in_btc', 'mean_out_btc']\n",
    "dataset_df.drop(columns=drop_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indegree</th>\n",
       "      <th>outdegree</th>\n",
       "      <th>in_btc</th>\n",
       "      <th>out_btc</th>\n",
       "      <th>total_btc</th>\n",
       "      <th>in_malicious</th>\n",
       "      <th>out_malicious</th>\n",
       "      <th>out_and_tx_malicious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.478187</td>\n",
       "      <td>0.476987</td>\n",
       "      <td>0.955174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.019000</td>\n",
       "      <td>2.018500</td>\n",
       "      <td>4.037500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.879800</td>\n",
       "      <td>5.879300</td>\n",
       "      <td>11.759100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.495906</td>\n",
       "      <td>0.495406</td>\n",
       "      <td>0.991312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   indegree  outdegree    in_btc   out_btc  total_btc  in_malicious  \\\n",
       "0         4          2  0.478187  0.476987   0.955174             0   \n",
       "1         3          2  2.019000  2.018500   4.037500             0   \n",
       "2         1          1  0.180100  0.180100   0.360200             0   \n",
       "3         1          2  5.879800  5.879300  11.759100             0   \n",
       "4         4          2  0.495906  0.495406   0.991312             0   \n",
       "\n",
       "   out_malicious  out_and_tx_malicious  \n",
       "0              0                     0  \n",
       "1              0                     0  \n",
       "2              0                     0  \n",
       "3              0                     0  \n",
       "4              0                     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Split Complete:\n",
      "Train Size: 72000\n",
      "Validation Size: 8000\n",
      "Test Size: 20000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "X = dataset_df.drop('out_and_tx_malicious', axis=1)\n",
    "y = dataset_df['out_and_tx_malicious']\n",
    "\n",
    "# Split dataset into Train (80%) and Test (20%) ensuring stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Further split Train into Train (90%) and Validation (10%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.10, stratify=y_train, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Data Split Complete:\")\n",
    "print(f\"Train Size: {X_train.shape[0]}\")\n",
    "print(f\"Validation Size: {X_val.shape[0]}\")\n",
    "print(f\"Test Size: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Transformation Complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define features for log transformation\n",
    "log_features = ['indegree', 'outdegree', 'in_btc', 'out_btc', 'total_btc']\n",
    "\n",
    "# Apply log transformation\n",
    "for df in [X_train, X_val, X_test]:  \n",
    "    df[log_features] = np.log1p(df[log_features])  # log1p avoids log(0)\n",
    "\n",
    "print(\"Log Transformation Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering Complete\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering Function\n",
    "def add_features(df):\n",
    "    df['out_malicious_to_total_btc'] = df['out_malicious'] / (df['total_btc'] + 1e-6)\n",
    "    df['log_total_btc'] = np.log1p(df['total_btc'])\n",
    "    df['out_malicious_in_btc_interaction'] = df['out_malicious'] * df['in_btc']\n",
    "    df['net_btc_flow'] = df['in_btc'] - df['out_btc']\n",
    "    return df\n",
    "\n",
    "# Apply feature engineering to Train, Validation, and Test sets\n",
    "X_train_fe = add_features(X_train)\n",
    "X_val_fe = add_features(X_val)\n",
    "X_test_fe = add_features(X_test)\n",
    "\n",
    "# Select the final set of features\n",
    "selected_features = [\n",
    "    'in_btc', 'out_btc', 'total_btc', 'out_malicious',\n",
    "    'out_malicious_to_total_btc', 'log_total_btc',\n",
    "    'out_malicious_in_btc_interaction', 'net_btc_flow'\n",
    "]\n",
    "\n",
    "X_train_final = X_train_fe[selected_features]\n",
    "X_val_final = X_val_fe[selected_features]\n",
    "X_test_final = X_test_fe[selected_features]\n",
    "\n",
    "print(\"Feature Engineering Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after SMOTE:\n",
      "out_and_tx_malicious\n",
      "0    71923\n",
      "1      719\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "\n",
    "# Apply SMOTE to handle class imbalance\n",
    "smote = SMOTE(sampling_strategy=0.01, random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_final, y_train)\n",
    "\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "print(pd.Series(y_train_smote).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling Complete\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Initialize RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Fit and transform Train set\n",
    "X_train_scaled = scaler.fit_transform(X_train_smote)\n",
    "\n",
    "# Transform Validation and Test sets using the same scaler\n",
    "X_val_scaled = scaler.transform(X_val_final)\n",
    "X_test_scaled = scaler.transform(X_test_final)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train_final.columns)\n",
    "X_val_scaled_df = pd.DataFrame(X_val_scaled, columns=X_val_final.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test_final.columns)\n",
    "\n",
    "print(\"Scaling Complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building - Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Program Files\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Local\\Temp\\ipykernel_11652\\2465991583.py\", line 1, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\__init__.py\", line 467, in <module>\n",
      "    importlib.import_module(\"keras.src.optimizers\")\n",
      "  File \"c:\\Program Files\\Python310\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\__init__.py\", line 2, in <module>\n",
      "    from keras.api import DTypePolicy\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\api\\__init__.py\", line 8, in <module>\n",
      "    from keras.api import activations\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\api\\activations\\__init__.py\", line 7, in <module>\n",
      "    from keras.src.activations import deserialize\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\__init__.py\", line 13, in <module>\n",
      "    from keras.src import visualization\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\visualization\\__init__.py\", line 1, in <module>\n",
      "    from keras.src.visualization import draw_bounding_boxes\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\visualization\\draw_bounding_boxes.py\", line 11, in <module>\n",
      "    import cv2\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\cv2\\__init__.py\", line 181, in <module>\n",
      "    bootstrap()\n",
      "  File \"C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\cv2\\__init__.py\", line 153, in bootstrap\n",
      "    native_module = importlib.import_module(\"cv2\")\n",
      "  File \"c:\\Program Files\\Python310\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set seed for reproducibility\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - Precision: 0.1516 - Recall: 0.1840 - loss: 1.4740 - val_Precision: 1.0000 - val_Recall: 0.5455 - val_loss: 0.0067\n",
      "Epoch 2/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - Precision: 0.6350 - Recall: 0.5177 - loss: 0.3083 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0165\n",
      "Epoch 3/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - Precision: 0.8634 - Recall: 0.5176 - loss: 0.0323 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0118\n",
      "Epoch 4/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - Precision: 0.9336 - Recall: 0.5189 - loss: 0.0529 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0086\n",
      "Epoch 5/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - Precision: 0.9690 - Recall: 0.5234 - loss: 0.0353 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0081\n",
      "Epoch 6/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - Precision: 0.9860 - Recall: 0.5426 - loss: 0.0211 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0066\n",
      "Epoch 7/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - Precision: 0.9746 - Recall: 0.5458 - loss: 0.0309 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0066\n",
      "Epoch 8/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - Precision: 0.9755 - Recall: 0.5519 - loss: 0.0561 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0067\n",
      "Epoch 9/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - Precision: 0.9602 - Recall: 0.5536 - loss: 0.0214 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0056\n",
      "Epoch 10/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - Precision: 0.9749 - Recall: 0.5509 - loss: 0.0322 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0047\n",
      "Epoch 11/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - Precision: 0.9606 - Recall: 0.5769 - loss: 0.0479 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0057\n",
      "Epoch 12/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - Precision: 0.9612 - Recall: 0.5618 - loss: 0.0228 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0061\n",
      "Epoch 13/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - Precision: 0.9464 - Recall: 0.5810 - loss: 0.0391 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0046\n",
      "Epoch 14/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - Precision: 0.9610 - Recall: 0.5687 - loss: 0.0416 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0057\n",
      "Epoch 15/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - Precision: 0.9332 - Recall: 0.5647 - loss: 0.0258 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0056\n",
      "Epoch 16/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - Precision: 0.9633 - Recall: 0.5658 - loss: 0.0195 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0053\n",
      "Epoch 17/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - Precision: 0.9575 - Recall: 0.5707 - loss: 0.0189 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0053\n",
      "Epoch 18/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - Precision: 0.9540 - Recall: 0.5716 - loss: 0.0243 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0055\n",
      "Epoch 19/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - Precision: 0.9338 - Recall: 0.5749 - loss: 0.0182 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0054\n",
      "Epoch 20/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - Precision: 0.9462 - Recall: 0.5916 - loss: 0.0220 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0052\n",
      "Epoch 21/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - Precision: 0.9240 - Recall: 0.5996 - loss: 0.0440 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0054\n",
      "Epoch 22/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - Precision: 0.9391 - Recall: 0.5956 - loss: 0.0383 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0055\n",
      "Epoch 23/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - Precision: 0.9536 - Recall: 0.5785 - loss: 0.0484 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0054\n",
      "Epoch 24/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - Precision: 0.9546 - Recall: 0.5859 - loss: 0.0369 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0048\n",
      "Epoch 25/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - Precision: 0.9435 - Recall: 0.6016 - loss: 0.0508 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0050\n",
      "Epoch 26/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - Precision: 0.9571 - Recall: 0.6007 - loss: 0.0179 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0053\n",
      "Epoch 27/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - Precision: 0.9582 - Recall: 0.5993 - loss: 0.0285 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0052\n",
      "Epoch 28/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - Precision: 0.9532 - Recall: 0.5966 - loss: 0.0183 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0052\n",
      "Epoch 29/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - Precision: 0.9605 - Recall: 0.6098 - loss: 0.0304 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0052\n",
      "Epoch 30/30\n",
      "\u001b[1m2271/2271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - Precision: 0.9553 - Recall: 0.6021 - loss: 0.0242 - val_Precision: 1.0000 - val_Recall: 0.6364 - val_loss: 0.0053\n"
     ]
    }
   ],
   "source": [
    "# Define the Neural Network architecture\n",
    "nn_model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # Input Layer\n",
    "    Dropout(0.3),  # Prevent overfitting\n",
    "    Dense(32, activation='relu'),  # Hidden Layer\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')  # Output Layer (binary classification)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "nn_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['Precision', 'Recall']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = nn_model.fit(\n",
    "    X_train_scaled, y_train_smote,\n",
    "    validation_data=(X_test_scaled, y_test),\n",
    "    epochs=30, batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95     19978\n",
      "           1       0.01      1.00      0.02        22\n",
      "\n",
      "    accuracy                           0.90     20000\n",
      "   macro avg       0.51      0.95      0.48     20000\n",
      "weighted avg       1.00      0.90      0.95     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Determine the optimal threshold using ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_nn)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Make Predictions\n",
    "y_pred_nn = (y_pred_proba_nn >= optimal_threshold).astype(int)\n",
    "\n",
    "# Print Classification Report\n",
    "print(\"\\nNeural Network Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Computed Class Weights: {0: np.float64(0.5005352946901548), 1: np.float64(467.53246753246754)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Compute class weights to handle imbalance\n",
    "# Compute class weights for imbalanced data\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "print(\"\\n✅ Computed Class Weights:\", class_weight_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def focal_loss(alpha=0.25, gamma=2.0):\n",
    "    def loss(y_true, y_pred):\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        pt = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        return -K.mean(alpha * K.pow(1.0 - pt, gamma) * K.log(pt))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m2,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,313</span> (177.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m45,313\u001b[0m (177.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,417</span> (173.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,417\u001b[0m (173.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Improved Model with Focal Loss, BatchNorm, Dropout\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train_scaled_df.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(1, activation='sigmoid')  # Output layer (binary classification)\n",
    "])\n",
    "\n",
    "# Compile Model with Focal Loss\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=focal_loss(),\n",
    "    metrics=['Precision', 'Recall', 'AUC']\n",
    ")\n",
    "\n",
    "# Print Model Summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1136/1136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - AUC: 0.7859 - Precision: 0.0535 - Recall: 0.6786 - loss: 0.1732 - val_AUC: 0.6780 - val_Precision: 0.0080 - val_Recall: 0.5556 - val_loss: 0.2242 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m1136/1136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - AUC: 0.9245 - Precision: 0.4135 - Recall: 0.7132 - loss: 0.0217 - val_AUC: 0.6541 - val_Precision: 0.0091 - val_Recall: 0.5556 - val_loss: 0.2104 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m1136/1136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - AUC: 0.9695 - Precision: 0.5180 - Recall: 0.7047 - loss: 0.0140 - val_AUC: 0.8931 - val_Precision: 0.0177 - val_Recall: 0.5556 - val_loss: 0.0931 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m1136/1136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - AUC: 0.9741 - Precision: 0.5656 - Recall: 0.7114 - loss: 0.0134 - val_AUC: 0.8771 - val_Precision: 0.0128 - val_Recall: 0.5556 - val_loss: 0.1314 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m1136/1136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - AUC: 0.9818 - Precision: 0.6184 - Recall: 0.6961 - loss: 0.0117 - val_AUC: 0.9024 - val_Precision: 0.0197 - val_Recall: 0.5556 - val_loss: 0.0872 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m1136/1136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - AUC: 0.9844 - Precision: 0.6707 - Recall: 0.7094 - loss: 0.0108 - val_AUC: 0.8949 - val_Precision: 0.0123 - val_Recall: 0.5556 - val_loss: 0.1351 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m1136/1136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - AUC: 0.9856 - Precision: 0.6792 - Recall: 0.7163 - loss: 0.0107 - val_AUC: 0.8802 - val_Precision: 0.0120 - val_Recall: 0.5556 - val_loss: 0.1386 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m1136/1136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - AUC: 0.9835 - Precision: 0.6738 - Recall: 0.6975 - loss: 0.0112 - val_AUC: 0.9081 - val_Precision: 0.0151 - val_Recall: 0.5556 - val_loss: 0.1090 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m1136/1136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - AUC: 0.9868 - Precision: 0.6458 - Recall: 0.7119 - loss: 0.0102 - val_AUC: 0.8848 - val_Precision: 0.0119 - val_Recall: 0.5556 - val_loss: 0.1464 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m1136/1136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - AUC: 0.9848 - Precision: 0.6824 - Recall: 0.6988 - loss: 0.0104 - val_AUC: 0.8634 - val_Precision: 0.0117 - val_Recall: 0.5556 - val_loss: 0.1437 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m1136/1136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - AUC: 0.9871 - Precision: 0.6814 - Recall: 0.6853 - loss: 0.0102 - val_AUC: 0.9105 - val_Precision: 0.0116 - val_Recall: 0.5556 - val_loss: 0.1458 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m1136/1136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - AUC: 0.9873 - Precision: 0.7046 - Recall: 0.6991 - loss: 0.0098 - val_AUC: 0.8929 - val_Precision: 0.0120 - val_Recall: 0.5556 - val_loss: 0.1414 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m1136/1136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - AUC: 0.9879 - Precision: 0.7130 - Recall: 0.7006 - loss: 0.0097 - val_AUC: 0.9413 - val_Precision: 0.0133 - val_Recall: 0.5556 - val_loss: 0.1274 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m1136/1136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - AUC: 0.9879 - Precision: 0.6897 - Recall: 0.7237 - loss: 0.0095 - val_AUC: 0.9423 - val_Precision: 0.0145 - val_Recall: 0.5556 - val_loss: 0.1164 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m1136/1136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - AUC: 0.9877 - Precision: 0.7343 - Recall: 0.7156 - loss: 0.0097 - val_AUC: 0.9411 - val_Precision: 0.0128 - val_Recall: 0.5556 - val_loss: 0.1336 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Reduce learning rate when loss plateaus\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(\n",
    "    X_train_smote, y_train_smote, \n",
    "    validation_data=(X_val_scaled_df, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=64, \n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "\n",
      "✅ Best Threshold: 0.9998209\n",
      "\n",
      "📊 Improved Neural Network Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     19978\n",
      "           1       0.03      0.59      0.06        22\n",
      "\n",
      "    accuracy                           0.98     20000\n",
      "   macro avg       0.52      0.79      0.52     20000\n",
      "weighted avg       1.00      0.98      0.99     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict Probabilities\n",
    "y_scores_nn = model.predict(X_test_scaled_df)\n",
    "\n",
    "# Find best threshold from PR curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_scores_nn)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "print(\"\\n✅ Best Threshold:\", best_threshold)\n",
    "\n",
    "# Convert Probabilities to Binary Predictions\n",
    "y_pred_nn = (y_scores_nn >= best_threshold).astype(int)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\n📊 Improved Neural Network Results:\")\n",
    "print(classification_report(y_test, y_pred_nn, zero_division=0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
