{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"C:/Users/Enduser/OneDrive - Asia Pacific University/uni/Y3S2/fyp/Model_trial/btc_trial_dataset2.csv\"\n",
    "dataset_df = pd.read_csv(df_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection: Dropping Irrelevant or Redundant Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['tx_hash', 'is_malicious', 'all_malicious', 'mean_in_btc', 'mean_out_btc','in_malicious']\n",
    "dataset_df.drop(columns=drop_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indegree</th>\n",
       "      <th>outdegree</th>\n",
       "      <th>in_btc</th>\n",
       "      <th>out_btc</th>\n",
       "      <th>total_btc</th>\n",
       "      <th>out_malicious</th>\n",
       "      <th>out_and_tx_malicious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.478187</td>\n",
       "      <td>0.476987</td>\n",
       "      <td>0.955174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.019000</td>\n",
       "      <td>2.018500</td>\n",
       "      <td>4.037500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.879800</td>\n",
       "      <td>5.879300</td>\n",
       "      <td>11.759100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.495906</td>\n",
       "      <td>0.495406</td>\n",
       "      <td>0.991312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   indegree  outdegree    in_btc   out_btc  total_btc  out_malicious  \\\n",
       "0         4          2  0.478187  0.476987   0.955174              0   \n",
       "1         3          2  2.019000  2.018500   4.037500              0   \n",
       "2         1          1  0.180100  0.180100   0.360200              0   \n",
       "3         1          2  5.879800  5.879300  11.759100              0   \n",
       "4         4          2  0.495906  0.495406   0.991312              0   \n",
       "\n",
       "   out_and_tx_malicious  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Split Complete:\n",
      "Train Size: 72000\n",
      "Validation Size: 8000\n",
      "Test Size: 20000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "X = dataset_df.drop('out_and_tx_malicious', axis=1)\n",
    "y = dataset_df['out_and_tx_malicious']\n",
    "\n",
    "# Split dataset into Train (80%) and Test (20%) ensuring stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Further split Train into Train (90%) and Validation (10%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.10, stratify=y_train, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Data Split Complete:\")\n",
    "print(f\"Train Size: {X_train.shape[0]}\")\n",
    "print(f\"Validation Size: {X_val.shape[0]}\")\n",
    "print(f\"Test Size: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling: Logarithmic Transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Transformation Complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define features for log transformation\n",
    "log_features = ['indegree', 'outdegree', 'in_btc', 'out_btc', 'total_btc']\n",
    "\n",
    "# Apply log transformation\n",
    "for df in [X_train, X_val, X_test]:  \n",
    "    df[log_features] = np.log1p(df[log_features])  # log1p avoids log(0)\n",
    "\n",
    "print(\"Log Transformation Complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering Complete\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering Function\n",
    "def add_features(df):\n",
    "    df['out_malicious_to_total_btc'] = df['out_malicious'] / (df['total_btc'] + 1e-6)\n",
    "    df['log_total_btc'] = np.log1p(df['total_btc'])\n",
    "    df['out_malicious_in_btc_interaction'] = df['out_malicious'] * df['in_btc']\n",
    "    df['net_btc_flow'] = df['in_btc'] - df['out_btc']\n",
    "    return df\n",
    "\n",
    "# Apply feature engineering to Train, Validation, and Test sets\n",
    "X_train_fe = add_features(X_train)\n",
    "X_val_fe = add_features(X_val)\n",
    "X_test_fe = add_features(X_test)\n",
    "\n",
    "# Select the final set of features\n",
    "selected_features = [\n",
    "    'in_btc', 'out_btc', 'total_btc', 'out_malicious', 'indegree','outdegree',\n",
    "    'out_malicious_to_total_btc', 'log_total_btc',\n",
    "    'out_malicious_in_btc_interaction', 'net_btc_flow'\n",
    "]\n",
    "\n",
    "X_train_final = X_train_fe[selected_features]\n",
    "X_val_final = X_val_fe[selected_features]\n",
    "X_test_final = X_test_fe[selected_features]\n",
    "\n",
    "print(\"Feature Engineering Complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Balancing - Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after SMOTE:\n",
      "out_and_tx_malicious\n",
      "0    71923\n",
      "1      719\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "\n",
    "# Apply SMOTE to handle class imbalance\n",
    "smote = SMOTE(sampling_strategy=0.01, random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_final, y_train)\n",
    "\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "print(pd.Series(y_train_smote).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling: Robust Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling Complete\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Initialize RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Fit and transform Train set\n",
    "X_train_scaled = scaler.fit_transform(X_train_smote)\n",
    "\n",
    "# Transform Validation and Test sets using the same scaler\n",
    "X_val_scaled = scaler.transform(X_val_final)\n",
    "X_test_scaled = scaler.transform(X_test_final)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train_final.columns)\n",
    "X_val_scaled_df = pd.DataFrame(X_val_scaled, columns=X_val_final.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test_final.columns)\n",
    "\n",
    "print(\"Scaling Complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "--------------------------------------------------\n",
      "Threshold: 0.10\n",
      "Recall: 0.6250, F1-Score: 0.1695, ROC AUC: 0.9660\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      7992\n",
      "           1       0.10      0.62      0.17         8\n",
      "\n",
      "    accuracy                           0.99      8000\n",
      "   macro avg       0.55      0.81      0.58      8000\n",
      "weighted avg       1.00      0.99      1.00      8000\n",
      "\n",
      "--------------------------------------------------\n",
      "Threshold: 0.30\n",
      "Recall: 0.6250, F1-Score: 0.2857, ROC AUC: 0.9660\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.19      0.62      0.29         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.59      0.81      0.64      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "--------------------------------------------------\n",
      "Threshold: 0.50\n",
      "Recall: 0.3750, F1-Score: 0.2222, ROC AUC: 0.9660\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.16      0.38      0.22         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.58      0.69      0.61      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "--------------------------------------------------\n",
      "Threshold: 0.70\n",
      "Recall: 0.1250, F1-Score: 0.0909, ROC AUC: 0.9660\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.07      0.12      0.09         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.54      0.56      0.54      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Best Threshold: 0.1, Best Recall: 0.625\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     19978\n",
      "           1       0.06      0.36      0.10        22\n",
      "\n",
      "    accuracy                           0.99     20000\n",
      "   macro avg       0.53      0.68      0.55     20000\n",
      "weighted avg       1.00      0.99      1.00     20000\n",
      "\n",
      "ROC AUC: 0.9598\n",
      "\n",
      "5-Fold CV Recall Scores: [0.65972222 0.64335664 0.625      0.65277778 0.63888889]\n",
      "Mean CV Recall: 0.6439, Std: 0.0119\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, roc_auc_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Initialize SVM with class weights\n",
    "svm_model = SVC(\n",
    "    kernel='rbf',           # Radial basis function kernel for non-linear separation\n",
    "    class_weight='balanced', # Adjust weights to emphasize fraud class\n",
    "    probability=True,       # Enable probability estimates for threshold tuning\n",
    "    random_state=42,\n",
    "    C=1.0                   # Regularization parameter \n",
    ")\n",
    "\n",
    "# Train the model \n",
    "svm_model.fit(X_train_scaled_df, y_train_smote)\n",
    "\n",
    "# Evaluate \n",
    "# Predict probabilities for threshold tuning\n",
    "y_val_proba = svm_model.predict_proba(X_val_scaled_df)[:, 1]\n",
    "\n",
    "# adjust threshold and evaluate\n",
    "def evaluate_threshold(y_true, y_proba, threshold):\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_proba)\n",
    "    print(f\"Threshold: {threshold:.2f}\")\n",
    "    print(f\"Recall: {recall:.4f}, F1-Score: {f1:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    return recall, f1, roc_auc\n",
    "\n",
    "# Test multiple thresholds\n",
    "thresholds = [0.1, 0.3, 0.5, 0.7]\n",
    "best_threshold = 0.5\n",
    "best_recall = 0\n",
    "\n",
    "print(\"Validation Set Performance:\")\n",
    "for thresh in thresholds:\n",
    "    print(\"-\" * 50)\n",
    "    recall, f1, roc_auc = evaluate_threshold(y_val, y_val_proba, thresh)\n",
    "    if recall > best_recall:  # Prioritize recall for fraud detection\n",
    "        best_recall = recall\n",
    "        best_threshold = thresh\n",
    "\n",
    "print(f\"Best Threshold: {best_threshold}, Best Recall: {best_recall}\")\n",
    "\n",
    "# Predictions on Test Set with Best Threshold\n",
    "y_test_proba = svm_model.predict_proba(X_test_scaled_df)[:, 1]\n",
    "y_test_pred = (y_test_proba >= best_threshold).astype(int)\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_test_proba):.4f}\")\n",
    "\n",
    "# Cross-Validation for Robustness\n",
    "cv_scores = cross_val_score(\n",
    "    svm_model, X_train_scaled_df, y_train_smote, cv=5, scoring='recall'\n",
    ")\n",
    "print(f\"\\n5-Fold CV Recall Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Recall: {cv_scores.mean():.4f}, Std: {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Model 2 with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "Threshold: 0.05, Recall: 0.7500, Precision: 0.0173, F1: 0.0338, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      7992\n",
      "           1       0.02      0.75      0.03         8\n",
      "\n",
      "    accuracy                           0.96      8000\n",
      "   macro avg       0.51      0.85      0.51      8000\n",
      "weighted avg       1.00      0.96      0.98      8000\n",
      "\n",
      "Threshold: 0.10, Recall: 0.5000, Precision: 0.0197, F1: 0.0379, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      7992\n",
      "           1       0.02      0.50      0.04         8\n",
      "\n",
      "    accuracy                           0.97      8000\n",
      "   macro avg       0.51      0.74      0.51      8000\n",
      "weighted avg       1.00      0.97      0.99      8000\n",
      "\n",
      "Threshold: 0.15, Recall: 0.1250, Precision: 0.0088, F1: 0.0164, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      7992\n",
      "           1       0.01      0.12      0.02         8\n",
      "\n",
      "    accuracy                           0.98      8000\n",
      "   macro avg       0.50      0.56      0.50      8000\n",
      "weighted avg       1.00      0.98      0.99      8000\n",
      "\n",
      "Threshold: 0.20, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.25, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.30, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.35, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.40, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.45, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.50, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.55, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.60, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.65, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.70, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.75, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.80, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.85, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.90, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Best Threshold: 0.5, Best F1: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19978\n",
      "           1       0.33      0.23      0.27        22\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       0.67      0.61      0.63     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n",
      "ROC AUC: 0.9524\n",
      "\n",
      "5-Fold CV Recall Scores: [0.27777778 0.30769231 0.29861111 0.29861111 0.28472222]\n",
      "Mean CV Recall: 0.2935, Std: 0.0108\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, roc_auc_score, recall_score, f1_score, precision_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#  Hyperparameter Tuning\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto', 0.1]}\n",
    "grid_search = GridSearchCV(\n",
    "    SVC(kernel='rbf', class_weight='balanced', probability=True, random_state=42),\n",
    "    param_grid, cv=5, scoring='recall', n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train_scaled, y_train_smote)\n",
    "best_svm = grid_search.best_estimator_\n",
    "\n",
    "# Calibrate Model\n",
    "svm_model = CalibratedClassifierCV(best_svm, method='sigmoid', cv=5)\n",
    "svm_model.fit(X_train_scaled, y_train_smote)\n",
    "\n",
    "# Evaluate on Validation Set\n",
    "y_val_proba = svm_model.predict_proba(X_val_scaled)[:, 1]\n",
    "thresholds = np.arange(0.05, 0.95, 0.05)\n",
    "best_threshold = 0.5\n",
    "best_score = 0\n",
    "\n",
    "print(\"Validation Set Performance:\")\n",
    "for thresh in thresholds:\n",
    "    y_val_pred = (y_val_proba >= thresh).astype(int)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred)\n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "    roc_auc = roc_auc_score(y_val, y_val_proba)\n",
    "    if recall >= 0.6 and precision > 0.1:\n",
    "        if f1 > best_score:\n",
    "            best_score = f1\n",
    "            best_threshold = thresh\n",
    "    print(f\"Threshold: {thresh:.2f}, Recall: {recall:.4f}, Precision: {precision:.4f}, F1: {f1:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "print(f\"Best Threshold: {best_threshold}, Best F1: {best_score}\")\n",
    "\n",
    "#  Test Set Performance\n",
    "y_test_proba = svm_model.predict_proba(X_test_scaled)[:, 1]\n",
    "y_test_pred = (y_test_proba >= best_threshold).astype(int)\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_test_proba):.4f}\")\n",
    "\n",
    "#  Cross-Validation\n",
    "cv_scores = cross_val_score(svm_model, X_train_scaled, y_train_smote, cv=5, scoring='recall')\n",
    "print(f\"\\n5-Fold CV Recall Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Recall: {cv_scores.mean():.4f}, Std: {cv_scores.std():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
