{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Split Complete:\n",
      "Train Size: 72000\n",
      "Validation Size: 8000\n",
      "Test Size: 20000\n",
      "Log Transformation Complete\n",
      "Feature Engineering Complete\n",
      "Class distribution after SMOTE:\n",
      "out_and_tx_malicious\n",
      "0    71922\n",
      "1      719\n",
      "Name: count, dtype: int64\n",
      "Scaling Complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Load your dataset (assuming this path is correct)\n",
    "df_path = \"C:/Users/Enduser/OneDrive - Asia Pacific University/uni/Y3S2/fyp/Model_trial/btc_trial_dataset2.csv\"\n",
    "dataset_df = pd.read_csv(df_path)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "drop_cols = ['tx_hash', 'is_malicious', 'all_malicious', 'mean_in_btc', 'mean_out_btc','in_malicious']\n",
    "dataset_df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "# Define features and target\n",
    "X = dataset_df.drop('out_and_tx_malicious', axis=1)\n",
    "y = dataset_df['out_and_tx_malicious']\n",
    "\n",
    "# Original dataset split: train (80%) and test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Further split training data: train (85%) and validation (15%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=42)\n",
    "\n",
    "print(\"Data Split Complete:\")\n",
    "print(f\"Train Size: {X_train.shape[0]}\")\n",
    "print(f\"Validation Size: {X_val.shape[0]}\")\n",
    "print(f\"Test Size: {X_test.shape[0]}\")\n",
    "\n",
    "# Log transformation\n",
    "log_features = ['indegree', 'outdegree', 'in_btc', 'out_btc', 'total_btc']\n",
    "for df in [X_train, X_val, X_test]:\n",
    "    df[log_features] = np.log1p(df[log_features])\n",
    "\n",
    "print(\"Log Transformation Complete\")\n",
    "\n",
    "# Feature Engineering Function\n",
    "def add_features(df):\n",
    "    df['out_malicious_to_total_btc'] = df['out_malicious'] / (df['total_btc'] + 1e-6)\n",
    "    df['log_total_btc'] = np.log1p(df['total_btc'])\n",
    "    df['out_malicious_in_btc_interaction'] = df['out_malicious'] * df['in_btc']\n",
    "    df['net_btc_flow'] = df['in_btc'] - df['out_btc']\n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "X_train_fe = add_features(X_train)\n",
    "X_val_fe = add_features(X_val)\n",
    "X_test_fe = add_features(X_test)\n",
    "\n",
    "# Select final features\n",
    "selected_features = [\n",
    "    'in_btc', 'out_btc', 'total_btc', 'out_malicious', 'indegree', 'outdegree',\n",
    "    'out_malicious_to_total_btc', 'log_total_btc',\n",
    "    'out_malicious_in_btc_interaction', 'net_btc_flow'\n",
    "]\n",
    "\n",
    "X_train_final = X_train_fe[selected_features]\n",
    "X_val_final = X_val_fe[selected_features]\n",
    "X_test_final = X_test_fe[selected_features]\n",
    "\n",
    "print(\"Feature Engineering Complete\")\n",
    "\n",
    "# Apply SMOTE (optional, but we'll also use LightGBM's native imbalance handling)\n",
    "smote = SMOTE(sampling_strategy=0.01, random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_final, y_train)\n",
    "\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "print(pd.Series(y_train_smote).value_counts())\n",
    "\n",
    "# Scaling with RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_smote)\n",
    "X_val_scaled = scaler.transform(X_val_final)\n",
    "X_test_scaled = scaler.transform(X_test_final)\n",
    "\n",
    "# Convert back to DataFrame for consistency\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train_final.columns)\n",
    "X_val_scaled_df = pd.DataFrame(X_val_scaled, columns=X_val_final.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test_final.columns)\n",
    "\n",
    "print(\"Scaling Complete\")\n",
    "\n",
    "# Prepare LightGBM Datasets\n",
    "train_data = lgb.Dataset(X_train_scaled_df, label=y_train_smote)\n",
    "val_data = lgb.Dataset(X_val_scaled_df, label=y_val, reference=train_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "--------------------------------------------------\n",
      "Threshold: 0.10\n",
      "Recall: 0.6250, F1-Score: 0.1695, ROC AUC: 0.9660\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      7992\n",
      "           1       0.10      0.62      0.17         8\n",
      "\n",
      "    accuracy                           0.99      8000\n",
      "   macro avg       0.55      0.81      0.58      8000\n",
      "weighted avg       1.00      0.99      1.00      8000\n",
      "\n",
      "--------------------------------------------------\n",
      "Threshold: 0.30\n",
      "Recall: 0.6250, F1-Score: 0.2857, ROC AUC: 0.9660\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.19      0.62      0.29         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.59      0.81      0.64      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "--------------------------------------------------\n",
      "Threshold: 0.50\n",
      "Recall: 0.3750, F1-Score: 0.2222, ROC AUC: 0.9660\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.16      0.38      0.22         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.58      0.69      0.61      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "--------------------------------------------------\n",
      "Threshold: 0.70\n",
      "Recall: 0.1250, F1-Score: 0.0909, ROC AUC: 0.9660\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.07      0.12      0.09         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.54      0.56      0.54      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Best Threshold: 0.1, Best Recall: 0.625\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     19978\n",
      "           1       0.06      0.36      0.10        22\n",
      "\n",
      "    accuracy                           0.99     20000\n",
      "   macro avg       0.53      0.68      0.55     20000\n",
      "weighted avg       1.00      0.99      1.00     20000\n",
      "\n",
      "ROC AUC: 0.9598\n",
      "\n",
      "5-Fold CV Recall Scores: [0.65972222 0.64335664 0.625      0.65277778 0.63888889]\n",
      "Mean CV Recall: 0.6439, Std: 0.0119\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, roc_auc_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Step 1: Initialize SVM with class weights\n",
    "svm_model = SVC(\n",
    "    kernel='rbf',           # Radial basis function kernel for non-linear separation\n",
    "    class_weight='balanced', # Adjust weights to emphasize fraud class\n",
    "    probability=True,       # Enable probability estimates for threshold tuning\n",
    "    random_state=42,\n",
    "    C=1.0                   # Regularization parameter (tune later if needed)\n",
    ")\n",
    "\n",
    "# Step 2: Train the model on SMOTE-processed and scaled training data\n",
    "svm_model.fit(X_train_scaled_df, y_train_smote)\n",
    "\n",
    "# Step 3: Evaluate on Validation Set\n",
    "# Predict probabilities for threshold tuning\n",
    "y_val_proba = svm_model.predict_proba(X_val_scaled_df)[:, 1]\n",
    "\n",
    "# Function to adjust threshold and evaluate\n",
    "def evaluate_threshold(y_true, y_proba, threshold):\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_proba)\n",
    "    print(f\"Threshold: {threshold:.2f}\")\n",
    "    print(f\"Recall: {recall:.4f}, F1-Score: {f1:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    return recall, f1, roc_auc\n",
    "\n",
    "# Test multiple thresholds\n",
    "thresholds = [0.1, 0.3, 0.5, 0.7]\n",
    "best_threshold = 0.5\n",
    "best_recall = 0\n",
    "\n",
    "print(\"Validation Set Performance:\")\n",
    "for thresh in thresholds:\n",
    "    print(\"-\" * 50)\n",
    "    recall, f1, roc_auc = evaluate_threshold(y_val, y_val_proba, thresh)\n",
    "    if recall > best_recall:  # Prioritize recall for fraud detection\n",
    "        best_recall = recall\n",
    "        best_threshold = thresh\n",
    "\n",
    "print(f\"Best Threshold: {best_threshold}, Best Recall: {best_recall}\")\n",
    "\n",
    "# Step 4: Final Predictions on Test Set with Best Threshold\n",
    "y_test_proba = svm_model.predict_proba(X_test_scaled_df)[:, 1]\n",
    "y_test_pred = (y_test_proba >= best_threshold).astype(int)\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_test_proba):.4f}\")\n",
    "\n",
    "# Step 5: Optional Cross-Validation for Robustness\n",
    "cv_scores = cross_val_score(\n",
    "    svm_model, X_train_scaled_df, y_train_smote, cv=5, scoring='recall'\n",
    ")\n",
    "print(f\"\\n5-Fold CV Recall Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Recall: {cv_scores.mean():.4f}, Std: {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "Threshold: 0.05, Recall: 0.7500, Precision: 0.0173, F1: 0.0338, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      7992\n",
      "           1       0.02      0.75      0.03         8\n",
      "\n",
      "    accuracy                           0.96      8000\n",
      "   macro avg       0.51      0.85      0.51      8000\n",
      "weighted avg       1.00      0.96      0.98      8000\n",
      "\n",
      "Threshold: 0.10, Recall: 0.5000, Precision: 0.0197, F1: 0.0379, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      7992\n",
      "           1       0.02      0.50      0.04         8\n",
      "\n",
      "    accuracy                           0.97      8000\n",
      "   macro avg       0.51      0.74      0.51      8000\n",
      "weighted avg       1.00      0.97      0.99      8000\n",
      "\n",
      "Threshold: 0.15, Recall: 0.1250, Precision: 0.0088, F1: 0.0164, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      7992\n",
      "           1       0.01      0.12      0.02         8\n",
      "\n",
      "    accuracy                           0.98      8000\n",
      "   macro avg       0.50      0.56      0.50      8000\n",
      "weighted avg       1.00      0.98      0.99      8000\n",
      "\n",
      "Threshold: 0.20, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.25, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.30, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.35, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.40, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.45, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.50, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.55, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.60, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.65, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.70, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.75, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.80, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.85, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Threshold: 0.90, Recall: 0.0000, Precision: 0.0000, F1: 0.0000, ROC AUC: 0.8954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7992\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       0.50      0.50      0.50      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Best Threshold: 0.5, Best F1: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Enduser\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19978\n",
      "           1       0.33      0.23      0.27        22\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       0.67      0.61      0.63     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n",
      "ROC AUC: 0.9524\n",
      "\n",
      "5-Fold CV Recall Scores: [0.27777778 0.30769231 0.29861111 0.29861111 0.28472222]\n",
      "Mean CV Recall: 0.2935, Std: 0.0108\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, roc_auc_score, recall_score, f1_score, precision_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Step 1: Scale Data First\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_val_scaled = scaler.transform(X_val)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # Step 2: Apply SMOTE\n",
    "# smote = SMOTE(k_neighbors=5, random_state=42)\n",
    "# X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "# X_train_smote_df = pd.DataFrame(X_train_smote, columns=X_train.columns)\n",
    "\n",
    "# Step 3: Hyperparameter Tuning\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto', 0.1]}\n",
    "grid_search = GridSearchCV(\n",
    "    SVC(kernel='rbf', class_weight='balanced', probability=True, random_state=42),\n",
    "    param_grid, cv=5, scoring='recall', n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train_scaled, y_train_smote)\n",
    "best_svm = grid_search.best_estimator_\n",
    "\n",
    "# Step 4: Calibrate Model\n",
    "svm_model = CalibratedClassifierCV(best_svm, method='sigmoid', cv=5)\n",
    "svm_model.fit(X_train_scaled, y_train_smote)\n",
    "\n",
    "# Step 5: Evaluate on Validation Set\n",
    "y_val_proba = svm_model.predict_proba(X_val_scaled)[:, 1]\n",
    "thresholds = np.arange(0.05, 0.95, 0.05)\n",
    "best_threshold = 0.5\n",
    "best_score = 0\n",
    "\n",
    "print(\"Validation Set Performance:\")\n",
    "for thresh in thresholds:\n",
    "    y_val_pred = (y_val_proba >= thresh).astype(int)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred)\n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "    roc_auc = roc_auc_score(y_val, y_val_proba)\n",
    "    if recall >= 0.6 and precision > 0.1:\n",
    "        if f1 > best_score:\n",
    "            best_score = f1\n",
    "            best_threshold = thresh\n",
    "    print(f\"Threshold: {thresh:.2f}, Recall: {recall:.4f}, Precision: {precision:.4f}, F1: {f1:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "print(f\"Best Threshold: {best_threshold}, Best F1: {best_score}\")\n",
    "\n",
    "# Step 6: Test Set Performance\n",
    "y_test_proba = svm_model.predict_proba(X_test_scaled)[:, 1]\n",
    "y_test_pred = (y_test_proba >= best_threshold).astype(int)\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_test_proba):.4f}\")\n",
    "\n",
    "# Step 7: Cross-Validation\n",
    "cv_scores = cross_val_score(svm_model, X_train_scaled, y_train_smote, cv=5, scoring='recall')\n",
    "print(f\"\\n5-Fold CV Recall Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Recall: {cv_scores.mean():.4f}, Std: {cv_scores.std():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
